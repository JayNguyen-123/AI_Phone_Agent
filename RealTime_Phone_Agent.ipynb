{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFNWwonE09tlHbnJPHCUHq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayNguyen-123/AI_Phone_Agent/blob/main/RealTime_Phone_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDxEE3FgfJIG"
      },
      "outputs": [],
      "source": [
        "impor json\n",
        "import os\n",
        "import base64\n",
        "import asyncio\n",
        "import websockets\n",
        "from fastapi import FastAPI, WebSocket, Request\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.websockets import WebSocketDisconnect\n",
        "from twilio.twiml.voice_response import VoiceResponse, Connect, Say, Stream\n",
        "from dotenv import load_dotenv\n",
        "import logging\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')      # requires OpenAI Realtime API Access\n",
        "PORT = int(os.getenv('PORT', 5050))\n"
      ],
      "metadata": {
        "id": "jQGPcXL6gbvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_MESSAGE = (\n",
        "    \"You are a helpful and bubbly AI assistant who answers any questions I ask\"\n",
        "\n",
        ")\n",
        "VOICE = 'alloy'\n",
        "LOG_EVENT_TYPES = [\n",
        "    'response.content.done', 'rate_limits.updated', 'response.done',\n",
        "    'input_audio_buffer.committed', 'input_audio_buffer.speech_stopped',\n",
        "    'input_audio_buffer.speech_started', 'response.create', 'session.created'\n",
        "]\n",
        "\n",
        "SHOW_TIMING_MATH = False\n",
        "app = FastAPI()\n",
        "if not OPENAI_API_KEY:\n",
        "  raise ValueError('Missing the OpenAI key. Please set it in the .env file.')\n"
      ],
      "metadata": {
        "id": "wp96igTNiyjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def index_page():\n",
        "  return \"<html><body><h1>Twilio Media Stream is running!</h1></body></html>\"\n",
        "\n",
        "@app.api_route(\"/incoming-call\", methods=[\"GET\", \"POST\"])\n",
        "async def handle_incoming_call(request: Request):\n",
        "  \"\"\"Handle incoming call and return TwiML response to connect to Media Stream.\"\"\"\n",
        "  logger.info(\"Receiving incoming call request from: %s\", request.client.host)\n",
        "  response = VoiceResponse()\n",
        "  host = request.url.hostname\n",
        "  connect = Connect()\n",
        "  connect.stream(url=f'wss://{host}/media-stream')\n",
        "  response.append(connect)\n",
        "  logger.info(\"Successfully created the TwiML response\")\n",
        "\n",
        "  return HTMLResponse(content=str(response), media_type=\"application/xml\")\n",
        "\n",
        "@app.websocket(\"/media-stream\")\n",
        "async def handle_media_stream(websocket: WebSocket):\n",
        "  \"\"\"Handle Websocket connections between Twilio and OpenAI.\"\"\"\n",
        "  print(\"Client connected\")\n",
        "  await websocket.accept()\n",
        "\n",
        "  async with websockets.connect(\n",
        "      'wss\"//api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01',\n",
        "      extra_headers = {\n",
        "          \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
        "          \"OpenAI-Beta\": \"realtime=v1\"\n",
        "      }\n",
        "  ) as openai_ws:\n",
        "       await send_session_update(openai_ws)\n",
        "\n",
        "       # Connection specific state\n",
        "       stream_sid = None\n",
        "       latest_media_timestamp = 0\n",
        "       last_assistant_item = None\n",
        "       mark_queue = []\n",
        "       response_start_timestamp_twilio = None\n",
        "\n",
        "       async def receive_from_twilio():\n",
        "        \"\"\"Receive audio data from Twilio and send it to the OpenAI Realtime API.\"\"\"\n",
        "        nonlocal stream_sid, latest_media_timestamp\n",
        "        try:\n",
        "          async for message in websocket.iter_text():\n",
        "            data = json.loads(message)\n",
        "            if data['event'] == 'media' and openai_ws.open:\n",
        "              latest_media_timestamp = int(data['media']['timestamp'])\n",
        "              audio_append = {\n",
        "                  \"type\": \"input_audio_buffer.append\",\n",
        "                  \"audio\": data['media']['payload']\n",
        "              }\n",
        "              await openai_ws.send(json.dumps(audio_append))\n",
        "\n",
        "            elif data['event'] == 'start':\n",
        "              stream_sid = data['start']['streamSid']\n",
        "              print(f\"Incoming stream has started {stream_sid}\")\n",
        "              response_start_timestamp_twilio = None\n",
        "              latest_media_timestamp = 0\n",
        "              last_assistant_item = None\n",
        "            elif data['event'] == 'mark':\n",
        "              if mark_queue:\n",
        "                mark_queue.pop(0)\n",
        "\n",
        "        except WebSocketDisconnect:\n",
        "          print(\"CLient disconnect.\")\n",
        "          if openai_ws.open:\n",
        "            await openai_ws.close()\n",
        "\n",
        "       async def send_to_twilio():\n",
        "        \"\"\"Receive events from the OpenAI Realtime API, send audio back to Twilio.\"\"\"\n",
        "        nonlocal stream_sid, last_assistant_item, response_start_timestamp_twilio\n",
        "        try:\n",
        "          async for openai_message in openai_ws:\n",
        "            response = json.loads(openai_message)\n",
        "            if response['type'] in LOG_EVENT_TYPES:\n",
        "              print(f\"Receive event: {response['type']}\", response)\n",
        "\n",
        "            if response.get('type') == 'response.audio.delta' and 'delta' in response:\n",
        "              audio_payload = base64.b64decode(base64.b64decode(response['delta'])).decode('utf-8')\n",
        "              audio_delta = {\n",
        "                  \"event\": \"media\",\n",
        "                  \"streamSid\": stream_sid,\n",
        "                  \"media\": {\n",
        "                      \"payload\": audio_payload\n",
        "                  }\n",
        "              }\n",
        "              await websocket.send_json(audio_delta)\n",
        "\n",
        "              if response_start_timestamp_twilio is None:\n",
        "                response_start_timestamp_twilio = latest_media_timestamp\n",
        "                if SHOW_TIMING_MATH:\n",
        "                  print(f\"Setting start timestamp for new response: {response_start_timestamp_twilio}ms\")\n",
        "\n",
        "              # Update last_assistant _item safely\n",
        "              if response.get('item_id'):\n",
        "                last_assistant_item = response['item_id']\n",
        "\n",
        "              await send_mark(websocket, stream_sid)\n",
        "\n",
        "            # Trigger an interruption. Your case might work better using 'input_audio_buffer.speech_stopped' or combining the two\n",
        "            if response.get('type') == 'input_audio_buffer.speech_started':\n",
        "              print(\"Speech started detected.\")\n",
        "              if last_assistant_item:\n",
        "                print(f\"Interrupting response with id: {last_assistant_item}\")\n",
        "                await handle_speech_start_event()\n",
        "        except Exception as e:\n",
        "          print(f\"Error in send_to_twilio: {e}\")\n",
        "\n",
        "       async def handle_speech_start_event():\n",
        "        \"\"\"Handle interruption when the caller's speech start.\"\"\"\n",
        "        nonlocal response_start_timestamp_twilio, last_assistant_item\n",
        "        print(\"Handling speech start event.\")\n",
        "        if mark_queue and response_start_timestamp_twilio is not None:\n",
        "          elapse_time = latest_media_timestamp - response_start_timestamp_twilio\n",
        "          if SHOW_TIMING_MATH:\n",
        "            print(f\"Calculating elapsed time for truncation: {latest_media_timestamp} - {response_start_timestamp_twilio} = {elapse_time}ms\")\n",
        "\n",
        "          if last_assistant_item:\n",
        "            if SHOW_TIMING_MATH:\n",
        "              print(f\"Trucating item with ID: {last_assistant_item}, Truncated at: {elapse_time}ms\")\n",
        "\n",
        "            truncate_event = {\n",
        "                \"type\": \"conversation.item.truncate\",\n",
        "                \"item_id\": last_assistant_item,\n",
        "                \"content_index\": 0,\n",
        "                \"audio_end_ms\": elapse_time\n",
        "            }\n",
        "            await openai_ws.send(json.dumps(truncate_event))\n",
        "\n",
        "\n",
        "          await websocket.send_json({\n",
        "              \"event\": \"clear\",\n",
        "              \"streamSid\": stream_sid\n",
        "          })\n",
        "\n",
        "          mark_queue.clear()\n",
        "          last_assistant_item = None\n",
        "          response_start_timestamp_twilio = None\n",
        "\n",
        "       async def send_mark(connection, stream_sid):\n",
        "        if stream_sid:\n",
        "          mark_event = {\n",
        "              \"event\": \"mark\",\n",
        "              \"streamSid\": stream_sid,\n",
        "              \"mark\": {\"name\": \"responsePart\"}\n",
        "          }\n",
        "          await connection.send_json(mark_event)\n",
        "          mark_queue.append(\"responsePart\")\n",
        "\n",
        "       await asyncio.gather(receive_from_twilio(), send_to_twilio())\n",
        "\n",
        "\n",
        "async def send_initial_conversation_item(openai_ws):\n",
        "  \"\"\"Send initial convsersation item if AI talk first.\"\"\"\n",
        "  initial_conversation_item = {\n",
        "      \"type\": \"conversation.item.create\",\n",
        "      \"item\": {\n",
        "          \"type\": \"message\",\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [{\n",
        "              \"type\": \"input_text\",\n",
        "              \"text\": \"Greet the user with 'Hello there! I am an AI voice assistant that will help you with any questions you may have. Please ask me anything you want to know.'\"\n",
        "              }]\n",
        "     }\n",
        "  }\n",
        "\n",
        "  await openai_ws.send(json.dumps(initial_conversation_item))\n",
        "  await openai_ws.send(json.dumps({\"type\": \"response.create\"}))\n",
        "\n",
        "async def send_session_update(openai_ws):\n",
        "  \"\"\"Send session update to OpenAI WebSocket.\"\"\"\n",
        "\n",
        "  session_update = {\n",
        "      \"type\": \"session.update\",\n",
        "      \"session\": {\n",
        "          \"turn_detection\": {\"type\": \"server_vad\"},\n",
        "          \"input_audio_format\": \"g711_ulaw\",\n",
        "          \"output_audio_format\": \"g711_ulaw\",\n",
        "          \"voice\": VOICE,\n",
        "          \"instructions\": SYSTEM_MESSAGE,\n",
        "          \"modalities\": [\"text\", \"audio\"],\n",
        "          \"temperature\": 0.8,\n",
        "      }\n",
        "  }\n",
        "  print(\"Sending session update: \", json.dumps(session_update))\n",
        "  await openao_ws.send(json.dumps(session_update))\n",
        "\n",
        "  await send_initial_conversation_item(openai_ws)\n",
        "\n",
        "if __name__==\"__name__\":\n",
        "  import uvicorn\n",
        "  uvicorn.run(app, host=\"0.0.0.0\", port=PORT)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "x_u7iGnlkH_m",
        "outputId": "b1a43e3c-d4af-4ad4-d566-1fc691259c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'app' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-891a229dbf7a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHTMLResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindex_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"<html><body><h1>Twilio Media Stream is running!</h1></body></html>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_route\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/incoming-call\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7HkuvT_emYmX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}